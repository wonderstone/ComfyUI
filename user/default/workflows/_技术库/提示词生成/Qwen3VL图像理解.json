{"id":"6dd0e905-4e8e-49b5-92d7-8b4075c93613","revision":0,"last_node_id":5,"last_link_id":2,"nodes":[{"id":1,"type":"MarkdownNote","pos":[-361.7899063650832,385.4500297213091],"size":[550,530],"flags":{},"order":0,"mode":0,"inputs":[],"outputs":[],"properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.4.1","input_ue_unconnectable":{}}},"widgets_values":["## **⚙️ Parameters**\n\n| Parameter | Description | Default | Range | Node(s) |\n| :---- | :---- | :---- | :---- | :---- |\n| **model\\_name** | The Qwen-VL model to use. | Qwen3-VL-4B-Instruct | \\- | Standard & Advanced |\n| **quantization** | On-the-fly quantization. Ignored for pre-quantized models (e.g., FP8). | 8-bit (Balanced) | 4-bit, 8-bit, None | Standard & Advanced |\n| **preset\\_prompt** | A selection of pre-defined prompts for common tasks. | \"Describe this...\" | Any text | Standard & Advanced |\n| **custom\\_prompt** | Overrides the preset prompt if provided. |  | Any text | Standard & Advanced |\n| **max\\_tokens** | Maximum number of new tokens to generate. | 1024 | 64-2048 | Standard & Advanced |\n| **keep\\_model\\_loaded** | Keep the model in VRAM for faster subsequent runs. | True | True/False | Standard & Advanced |\n| **seed** | A seed for reproducible results. | 1 | 1 \\- 2^64-1 | Standard & Advanced |\n| **temperature** | Controls randomness. Higher values \\= more creative. (Used when num\\_beams is 1). | 0.6 | 0.1-1.0 | Advanced Only |\n| **top\\_p** | Nucleus sampling threshold. (Used when num\\_beams is 1). | 0.9 | 0.0-1.0 | Advanced Only |\n| **num\\_beams** | Number of beams for beam search. \\> 1 disables temperature/top\\_p sampling. | 1 | 1-10 | Advanced Only |\n| **repetition\\_penalty** | Discourages repeating tokens. | 1.2 | 0.0-2.0 | Advanced Only |\n| **frame\\_count** | Number of frames to sample from the video input. | 16 | 1-64 | Advanced Only |\n| **device** | Override automatic device selection. | auto | auto, cuda, cpu | Advanced Only |"],"color":"#432","bgcolor":"#653"},{"id":2,"type":"LoadImage","pos":[218.2100936349168,375.4500297213091],"size":[300,400],"flags":{},"order":1,"mode":0,"inputs":[],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[2]},{"name":"MASK","type":"MASK","links":null}],"properties":{"Node name for S&R":"LoadImage"},"widgets_values":["00002_1936422288.png"],"color":"#2e3e57","bgcolor":"#4b5b73"},{"id":3,"type":"PreviewAny","pos":[948.2100936349168,375.4500297213091],"size":[890,350],"flags":{},"order":2,"mode":0,"inputs":[{"localized_name":"source","name":"source","type":"*","link":1}],"outputs":[],"properties":{"cnr_id":"comfy-core","ver":"0.3.65","ue_properties":{"widget_ue_connectable":{},"input_ue_unconnectable":{},"version":"7.3"},"Node name for S&R":"PreviewAny","enableTabs":false,"tabWidth":65,"tabXOffset":10,"hasSecondTab":false,"secondTabText":"Send Back","secondTabOffset":80,"secondTabWidth":65},"widgets_values":[],"color":"#42526b","bgcolor":"#2e3e57"},{"id":4,"type":"AILab_QwenVL","pos":[533.2100936349168,375.4500297213091],"size":[400,300],"flags":{},"order":3,"mode":0,"inputs":[{"localized_name":"image","name":"image","shape":7,"type":"IMAGE","link":2},{"localized_name":"video","name":"video","shape":7,"type":"IMAGE","link":null},{"localized_name":"model_name","name":"model_name","type":"COMBO","widget":{"name":"model_name"},"link":null},{"localized_name":"quantization","name":"quantization","type":"COMBO","widget":{"name":"quantization"},"link":null},{"localized_name":"attention_mode","name":"attention_mode","type":"COMBO","widget":{"name":"attention_mode"},"link":null},{"localized_name":"preset_prompt","name":"preset_prompt","type":"COMBO","widget":{"name":"preset_prompt"},"link":null},{"localized_name":"custom_prompt","name":"custom_prompt","type":"STRING","widget":{"name":"custom_prompt"},"link":null},{"localized_name":"max_tokens","name":"max_tokens","type":"INT","widget":{"name":"max_tokens"},"link":null},{"localized_name":"keep_model_loaded","name":"keep_model_loaded","type":"BOOLEAN","widget":{"name":"keep_model_loaded"},"link":null},{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":null}],"outputs":[{"localized_name":"RESPONSE","name":"RESPONSE","type":"STRING","links":[1]}],"properties":{"cnr_id":"comfyui_fearnworksnodes","ver":"0.1.2","ue_properties":{"widget_ue_connectable":{},"input_ue_unconnectable":{},"version":"7.4.1"},"Node name for S&R":"AILab_QwenVL"},"widgets_values":["Qwen3-VL-8B-NSFW-Caption-V4.5","None (FP16)","sdpa","🖼️ Simple Description","1024",64,true,4100845932,"randomize"],"color":"#42526b","bgcolor":"#2e3e57"},{"id":5,"type":"MarkdownNote","pos":[-361.7899063650832,955.4500297213091],"size":[550,450],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.4.1","input_ue_unconnectable":{}}},"widgets_values":["## 🚀 **Dynamic Quantization Guide**\n\n### 📊 **Current Model**\n- **Model**: Qwen3-VL-8B-NSFW-Caption-V4.5 ✅\n- **Type**: Local Download (SafeTensors)\n- **Size**: 16.35 GB (FP16)\n\n### ⚡ **On-the-Fly Quantization Options**\nNo need to download new models! Quantize at runtime:\n\n| Quantization | VRAM | Speed | Quality | First Load |\n|:---|:---|:---|:---|:---|\n| **None (FP16)** | ~16 GB | Baseline | Best | Fast |\n| **8-bit** | ~9 GB | Fast | Excellent | ~30s |\n| **4-bit** | ~5.5 GB | Fastest | Very Good | ~30s |\n\n### 💡 **How to Use**\n1. Change **quantization** dropdown in QwenVL node\n2. First run quantizes the model (one-time)\n3. Subsequent runs use cached quantization\n\n### 📝 **Notes**\n- Quantization happens on first load only\n- Restart ComfyUI to clear cache\n- 4-bit is best for low VRAM systems"],"color":"#234","bgcolor":"#456"}],"links":[[1,4,0,3,0,"*"],[2,2,0,4,0,"IMAGE"]],"groups":[],"config":{},"extra":{"ue_links":[],"ds":{"scale":0.6308868299625973,"offset":[2151.3343165201245,255.4079642926027]}},"version":0.4}
